apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: prepare-a-case
    prometheus: cloud-platform
  name: pic-prometheus-k8s
  namespace: court-probation-prod
spec:
  groups:
  - name: PIC-apps
    rules:
    - alert: ErrorResponses
      annotations:
        message: ingress {{ $labels.ingress }} is serving 5XX responses
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        avg(rate(nginx_ingress_controller_request_duration_seconds_count{exported_namespace="court-probation-prod", status=~"5.*", ingress!="court-case-service"}[1m]) * 60 > 0) by (ingress)
      for: 1m
      labels:
        severity: prepare-a-case
    - alert: ErrorResponsesCCS
      annotations:
        message: ingress {{ $labels.ingress }} is serving 5XX responses
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        avg(rate(nginx_ingress_controller_request_duration_seconds_count{exported_namespace="court-probation-prod", status=~"5.*", ingress="court-case-service"}[1m]) * 60 > 4)
      for: 1m
      labels:
        severity: prepare-a-case
    - alert: KubeQuotaExceeded
      annotations:
        message: Namespace {{ $labels.namespace }} is using {{ printf "%0.0f" $value
          }}% of its {{ $labels.resource }} quota.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        100 * kube_resourcequota{namespace="court-probation-prod", job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{namespace="court-probation-prod", job="kube-state-metrics", type="hard"} > 0)
          > 90
      for: 15m
      labels:
        severity: prepare-a-case
    - alert: KubePodCrashLooping
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
          }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: rate(kube_pod_container_status_restarts_total{namespace="court-probation-prod", job="kube-state-metrics"}[15m])
        * 60 * 5 > 0
      for: 1h
      labels:
        severity: prepare-a-case
    - alert: KubePodNotReady
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready
          state for longer than an hour.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: sum by (namespace, pod) (kube_pod_status_phase{namespace="court-probation-prod", job="kube-state-metrics",
        phase=~"Pending|Unknown"}) > 0
      for: 1h
      labels:
        severity: prepare-a-case
    - alert: KubeDeploymentGenerationMismatch
      annotations:
        message: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment
          }} does not match, this indicates that the Deployment has failed but has
          not been rolled back.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        kube_deployment_status_observed_generation{namespace="court-probation-prod", job="kube-state-metrics"}
          !=
        kube_deployment_metadata_generation{namespace="court-probation-prod", job="kube-state-metrics"}
      for: 15m
      labels:
        severity: prepare-a-case
    - alert: KubeDeploymentReplicasMismatch
      annotations:
        message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not
          matched the expected number of replicas for longer than an hour.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        kube_deployment_spec_replicas{namespace="court-probation-prod", job="kube-state-metrics"}
          !=
        kube_deployment_status_replicas_available{namespace="court-probation-prod", job="kube-state-metrics"}
      for: 1h
      labels:
        severity: prepare-a-case
    - alert: RDSHighCpuCourtCaseService
      annotations:
        message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has high CPU (>95%) for more than ten minutes.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        aws_rds_cpuutilization_average{dbinstance_identifier="cloud-platform-37a1ac1b9a12702e"} > 95
      for: 10m
      labels:
        severity: prepare-a-case
    - alert: RDSHighCpuPreSentenceService
      annotations:
        message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has high CPU (>95%) for more than five minutes.
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        aws_rds_cpuutilization_average{dbinstance_identifier="cloud-platform-e98703fc54157c2d"} > 95
      for: 5m
      labels:
        severity: prepare-a-case
    - alert: pre-sentence-service-wproofreader-serving-5xx
      annotations:
        message: Pre Sentence Service wproofreader is returning 5xx responses
        runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/NDSS/pages/2680750089/Monitoring+and+Alerting
      expr: |-
        sum(rate(nginx_ingress_controller_requests{ingress=~"pre-sentence-service-wproofreader-v1-2", exported_namespace="laa-apply-for-legalaid-production", status=~"5.."}[5m]))*270 > 0
      for: 10m
      labels:
        severity: prepare-a-case  
