# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
# This file contains Prometheus alerting rules for the justice-gov-uk-production namespace.
# The alert severity labels determine which alertmanager receiver the alerts are sent to.
# ‼️ Critical alert - send to hale-platform-alerts
# ⚠️ Warning alert - send to justice-gov-uk-production-alerts
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  namespace: intranet-production
  labels:
    prometheus: prometheus-operator
    role: alert-rules
    release: prometheus-operator
  name: monitoring-rules-intranet
spec:
  groups:
    - name: kubernetes-apps
      rules:
        - alert: KubeQuotaAlmostFull # ‼️ Critical alert
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
            runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotaalmostfull
            summary: Namespace quota is going to be full.
          expr: |
            kube_resourcequota{job="kube-state-metrics", type="used", namespace="intranet-production"}
              / ignoring(instance, job, type)
            (kube_resourcequota{job="kube-state-metrics", type="hard", namespace="intranet-production"} > 0)
              > 0.9 < 1
          for: 15m
          labels:
            severity: hale-platform-alerts
        - alert: KubeQuota-Exceeded # ‼️ Critical alert
          annotations:
            message: Namespace {{ $labels.namespace }} is using {{ printf "%0.0f" $value
              }}% of its {{ $labels.resource }} quota.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded
          expr: |-
            100 * kube_resourcequota{job="kube-state-metrics", type="used", namespace="intranet-production"} 
            / ignoring(instance, job, type)
            (kube_resourcequota{job="kube-state-metrics", type="hard", namespace="intranet-production"} > 0)
            > 90
          for: 15m
          labels:
            severity: hale-platform-alerts
        - alert: KubePodCrashLooping # ‼️ Critical alert
          # pint file/disable alerts/template
          annotations:
            message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
              }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
          expr: |-
            rate(kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace="intranet-production"}[5m]) * 60 > 0
          for: 5m
          labels:
            severity: hale-platform-alerts
        - alert: KubePodNotReady
          annotations:
            message: A single pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready
              state for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
          expr: |-
            sum by (namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown", namespace="intranet-production"}) 
            > 0
          for: 15m
          labels:
            severity: intranet-production
        - alert: KubePodsMultipleNotReady # ‼️ Critical alert
          annotations:
            message: 2 or more pods in {{ $labels.namespace }} have been in a non-ready
              state for longer than 5 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
          expr: |-
            sum by (namespace) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown", namespace="intranet-production"}) 
            >= 2
          for: 5m
          labels:
            severity: hale-platform-alerts
        - alert: KubeDeploymentGenerationMismatch # ‼️ Critical alert
          annotations:
            message: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment
              }} does not match, this indicates that the Deployment has failed but has
              not been rolled back.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
          expr: |-
            kube_deployment_status_observed_generation{job="kube-state-metrics", namespace="intranet-production"}
            !=
            kube_deployment_metadata_generation{job="kube-state-metrics", namespace="intranet-production"}
          for: 15m
          labels:
            severity: hale-platform-alerts

    - name: application-rules
      rules:
      - alert: ServiceInsufficientAccessPolicy
        expr: http_status_code_wp_home{namespace="intranet-production"} != 401
        for: 1m
        labels:
          severity: intranet-production
        annotations:
          message: Namespace {{ $labels.namespace }} (homepage) is returning an unexpected status code {{ printf "%0.0f" $value}}.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+runbooks#ServiceInsufficientAccessPolicy
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/d/bdwyqxz07sxkwg/intranet-service?orgId=1&var-namespace=intranet-production

      - alert: ServiceAbsentAccessPolicy
        expr: absent(http_status_code_wp_home{namespace="intranet-production"}) == 1
        for: 15m
        labels:
          severity: intranet-production
        annotations:
          message: Namespace {{ $labels.namespace }} (homepage) is not returning a status code.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+runbooks#ServiceAbsentAccessPolicy
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/d/bdwyqxz07sxkwg/intranet-service?orgId=1&var-namespace=intranet-production

      - alert: ServiceInsufficientHeaderHandling
        expr: http_status_code_invalid_header{namespace="intranet-production"} != 400
        for: 1m
        labels:
          severity: intranet-production
        annotations:
          message: Namespace {{ $labels.namespace }} (invalid header) is returning an unexpected status code {{ printf "%0.0f" $value}}.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+runbooks#ServiceInsufficientHeaderHandling
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/d/bdwyqxz07sxkwg/intranet-service?orgId=1&var-namespace=intranet-production

    - name: rds-rules
      rules:
      - alert: RDSInstanceReadIOPSHigh # ‼️ Critical alert
        expr: aws_rds_read_iops_average{dbinstance_identifier="cloud-platform-283c8dc3f78ede0f"} > 1000
        for: 0m
        labels:
          severity: hale-platform-alerts
        annotations:
          message: RDS instance {{ $labels.dbinstance_identifier }} read IOPS is above 1000.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+PHP+NodeJS+runbooks#RDSInstanceReadIOPSHigh
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/goto/LwC6lOgDR?orgId=1
      - alert: RDSInstanceReadIOPSVeryHigh # ‼️ Critical alert
        expr: aws_rds_read_iops_average{dbinstance_identifier="cloud-platform-283c8dc3f78ede0f"} > 4000
        for: 0m
        labels:
          severity: hale-platform-alerts
        annotations:
          message: RDS instance {{ $labels.dbinstance_identifier }} read IOPS is above 4000.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+PHP+NodeJS+runbooks#RDSInstanceReadIOPSVeryHigh
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/goto/LwC6lOgDR?orgId=1
      - alert: RDSInstanceFreeableMemoryLow # ‼️ Critical alert
        expr: aws_rds_freeable_memory_average{dbinstance_identifier="cloud-platform-283c8dc3f78ede0f"} < 1800000000
        for: 0m
        labels:
          severity: hale-platform-alerts
        annotations:
          message: RDS instance {{ $labels.dbinstance_identifier }} freeable memory is below 1.8GiB.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+PHP+NodeJS+runbooks#RDSInstanceFreeableMemoryLow
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/goto/LwC6lOgDR?orgId=1

    - name: elasticache-rules
      rules:
      - alert: ElastiCacheCPUUtilizationHigh # ‼️ Critical alert
        expr: aws_elasticache_cpuutilization_average{cache_cluster_id=~"cp-78d7f414c59df971-00[12]"} > 70
        for: 0m
        labels:
          severity: hale-platform-alerts
        annotations:
          message: ElastiCache instance {{ $labels.cache_cluster_id }} CPU utilization is above 70%.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+PHP+NodeJS+runbooks#ElastiCacheCPUUtilizationHigh
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/goto/XWHVBzmvR?orgId=1
      - alert: ElastiCacheFreeableMemoryLow # ‼️ Critical alert
        expr: aws_elasticache_freeable_memory_average{cache_cluster_id=~"cp-78d7f414c59df971-00[12]"} < 500000000
        for: 0m
        labels:
          severity: hale-platform-alerts
        annotations:
          message: ElastiCache instance {{ $labels.cache_cluster_id }} freeable memory is below 500MB.
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+PHP+NodeJS+runbooks#ElastiCacheFreeableMemoryLow
          dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/goto/XWHVBzmvR?orgId=1

    - name: cronjob-alerts
      rules:
      - alert: WpCronJobStuck # ‼️ Critical alert
        expr: |
          (
            time() - kube_cronjob_status_last_successful_time{
              cronjob="wp-cron-trigger",
              namespace="intranet-production"
            }
          ) > 300
        for: 0s
        labels:
          severity: hale-platform-alerts
        annotations:
          summary: "WordPress cron job hasn't run successfully in over 5 minutes"
          runbook_url: https://dsdmoj.atlassian.net/wiki/spaces/CDPT/pages/5124292758/Alerts+PHP+NodeJS+runbooks#WpCronJobStuck
